{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bayesian Neural Networks",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to train a simple neural network architecture with bayesian inferencing"
      ],
      "metadata": {
        "id": "mfGWmrRHoAVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torch "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIaO0ebqPS2G",
        "outputId": "2e614fc1-fbb9-4672-ab35-a6ccf041d90f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pyro-ppl==1.4.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdOE4XBMQqj2",
        "outputId": "9c4c57a8-476b-4421-98d4-84d3b3a8a0e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyro-ppl==1.4.0 in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.4.0) (1.10.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.4.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.4.0) (1.19.5)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.4.0) (0.1.2)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.4.0) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->pyro-ppl==1.4.0) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy==1.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsY_atAoPNGi",
        "outputId": "b3cb97f3-6c58-437d-9fe0-f1f758aeeeed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hRyYp6LUO548"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "from IPython import display\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from scipy.misc import imread"
      ],
      "metadata": {
        "id": "ZBVKksSUPBNn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyro\n",
        "from pyro.distributions import Normal, Categorical\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam"
      ],
      "metadata": {
        "id": "nP06ePemPFWS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Nk2UP0JBPE4b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a simple neural network architecture"
      ],
      "metadata": {
        "id": "_r6WHzxBgLgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(nn.Module):\n",
        "    \"\"\" Defining a fully connected layer with an output layer \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        output = self.fc1(x)\n",
        "        output = F.relu(output)\n",
        "        output = self.out(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "5H7ry0rwPFPi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The softmax function is a good way of normalizing any value from [-infy, +infy] by applying an exponential function. However, it may create issues sometimes as we get large output values for small values of input. For example,\n",
        "\n",
        "As the numbers are too big the exponents will probably blow up (computer cannot handle such big numbers) giving Nan as output.\n",
        "\n",
        "From the softmax probabilities above, we can deduce that softmax can become numerically unstable for values with a very large range. Consider these values,\n",
        "x = np.array([10, 2, 10000, 4])\n",
        "print(softmax(x))\n",
        "\n",
        "output: [0.0,  0.0, nan,  0.0]\n",
        "\n",
        "\n",
        "\n",
        "Log softmax is the log of softmax function, mathematically,\n",
        "\n",
        "zi - log(summation of exponentials of all zi's)\n",
        "\n",
        "lesser computations of divisions and multiplications as addition is less computationally expensive.\n"
      ],
      "metadata": {
        "id": "2nkcC2rTgofW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_softmax = nn.LogSoftmax(dim=1) #takes log of the softmax output for fast \n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "softplus = torch.nn.Softplus()\n",
        "relu = nn.ReLU()"
      ],
      "metadata": {
        "id": "kbEfEUlCRANL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('mnist-data/', train=True, download=True,\n",
        "                       transform=transforms.Compose([transforms.ToTensor(),])),\n",
        "        batch_size=128, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('mnist-data/', train=False, transform=transforms.Compose([transforms.ToTensor(),])\n",
        "                       ),\n",
        "        batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "YQf83tzfPFR-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = NN(28*28, 1024, 10)"
      ],
      "metadata": {
        "id": "AeZJJFRkPFUS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('0', '1', '2', '3',\n",
        "           '4', '5', '6', '7', '8', '9')"
      ],
      "metadata": {
        "id": "1Mg1VjiBP78t"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(img):\n",
        "  \"\"\"Displaying an image \"\"\"\n",
        "  npimg = img.numpy()\n",
        "  fig, ax = plt.subplots(figsize=(1, 1))\n",
        "  ax.imshow(npimg,  cmap='gray', interpolation='nearest')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "8gtFf7afP9Z6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A quick note on softplus : \n",
        "The Softplus function is a smooth approximation of the ReLU function that removes the knee in the ReLU function graph and replaces it with a smooth curve.\n",
        "the output is always positive!"
      ],
      "metadata": {
        "id": "4O_O_PQ66FIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def guide(x_data, y_data):\n",
        "    \"\"\" This function is used for training the weights and biases distribution and optimise the model\"\"\"\n",
        "    # First layer weight distribution priors\n",
        "    fc1w_mu = torch.randn_like(net.fc1.weight)\n",
        "    fc1w_sigma = torch.randn_like(net.fc1.weight)\n",
        "    fc1w_mu_param = pyro.param(\"fc1w_mu\", fc1w_mu)\n",
        "    fc1w_sigma_param = softplus(pyro.param(\"fc1w_sigma\", fc1w_sigma))\n",
        "    fc1w_prior = Normal(loc=fc1w_mu_param, scale=fc1w_sigma_param)\n",
        "    # First layer bias distribution priors\n",
        "    fc1b_mu = torch.randn_like(net.fc1.bias)\n",
        "    fc1b_sigma = torch.randn_like(net.fc1.bias)\n",
        "    fc1b_mu_param = pyro.param(\"fc1b_mu\", fc1b_mu)\n",
        "    fc1b_sigma_param = softplus(pyro.param(\"fc1b_sigma\", fc1b_sigma))\n",
        "    fc1b_prior = Normal(loc=fc1b_mu_param, scale=fc1b_sigma_param)\n",
        "    # Output layer weight distribution priors\n",
        "    outw_mu = torch.randn_like(net.out.weight)\n",
        "    outw_sigma = torch.randn_like(net.out.weight)\n",
        "    outw_mu_param = pyro.param(\"outw_mu\", outw_mu)\n",
        "    outw_sigma_param = softplus(pyro.param(\"outw_sigma\", outw_sigma))\n",
        "    outw_prior = Normal(loc=outw_mu_param, scale=outw_sigma_param).independent(1)\n",
        "    # Output layer bias distribution priors\n",
        "    outb_mu = torch.randn_like(net.out.bias)\n",
        "    outb_sigma = torch.randn_like(net.out.bias)\n",
        "    outb_mu_param = pyro.param(\"outb_mu\", outb_mu)\n",
        "    outb_sigma_param = softplus(pyro.param(\"outb_sigma\", outb_sigma))\n",
        "    outb_prior = Normal(loc=outb_mu_param, scale=outb_sigma_param)\n",
        "    priors = {'fc1.weight': fc1w_prior, 'fc1.bias': fc1b_prior, 'out.weight': outw_prior, 'out.bias': outb_prior}\n",
        "    \n",
        "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
        "    \n",
        "    return lifted_module()"
      ],
      "metadata": {
        "id": "aB4gpjApPFau"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialising all bias and weights with normal distribution at the start, hence the likelihood of the parameters representing the data will be very low.\n",
        "\n",
        "In the model() function, we have defined P(A) — the priors on weights and biases."
      ],
      "metadata": {
        "id": "H0meoGylivRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(x_data, y_data):\n",
        "    \"\"\" We define the priors on weights and biases \"\"\"\n",
        "    fc1w_prior = Normal(loc=torch.zeros_like(net.fc1.weight), scale=torch.ones_like(net.fc1.weight))\n",
        "    fc1b_prior = Normal(loc=torch.zeros_like(net.fc1.bias), scale=torch.ones_like(net.fc1.bias))\n",
        "    \n",
        "    outw_prior = Normal(loc=torch.zeros_like(net.out.weight), scale=torch.ones_like(net.out.weight))\n",
        "    outb_prior = Normal(loc=torch.zeros_like(net.out.bias), scale=torch.ones_like(net.out.bias))\n",
        "    \n",
        "    priors = {'fc1.weight': fc1w_prior, 'fc1.bias': fc1b_prior,  'out.weight': outw_prior, 'out.bias': outb_prior}\n",
        "    # lift module parameters to random variables sampled from the priors\n",
        "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
        "    # sample a regressor (which also samples w and b)\n",
        "    lifted_reg_model = lifted_module()\n",
        "    \n",
        "    lhat = log_softmax(lifted_reg_model(x_data))\n",
        "\n",
        "    event_dim = max(lhat.dim() - 1, y_data.dim())\n",
        "    #telling the model that the output is a categorical variable equal to 10 classes\n",
        "    pyro.sample(\"obs\", Categorical(logits=lhat).to_event(event_dim), obs=y_data)"
      ],
      "metadata": {
        "id": "1iXZ1fGbPFYs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim = Adam({\"lr\": 0.001})\n",
        "svi = SVI(model, guide, optim, loss=Trace_ELBO())"
      ],
      "metadata": {
        "id": "aW7bqhA0PFc7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since calculating the \"Evidence\" in the denominator of bayes theorem is very time consuming, because :\n",
        "1. Hypothetically, values of parameters Aj could range from -infinity to +infinity\n",
        "2. For each value of Aj in that range, you have to run the model to find the likelihood of generating the input, output pairs you observe (the total dataset could be in millions of pairs)\n",
        "3. There could be not one but many such parameters (j >> 1). In fact, for a neural network of our size, we have ~8million parameters (number of weights = 1024*28*28*10).\n",
        "\n",
        "\n",
        "Hence, we try to use variational bayes method where we find the closest distribution (for example gaussian) to the posterior.\n",
        "\n",
        "The gist of Variational Bayes methods is that since we can’t exactly compute the posterior, we can find the closest probability distribution to it that is a surrogate disribution with small set of paramters like mean or variance. So, after random initialization of those parameters in a “surrogate” distribution, you can do gradient descent and modify parameters of the distribution (like mean or variance) a little bit each time to see if the resulting distribution is closer to the posterior that you want to calculate. (If you’re thinking how do we know if resulting distribution is closer to the posterior if posterior is exactly what we want to calculate, you’ve understood the idea. The answer is that, surprisingly, we don’t need the exact posterior to find closeness between it and the other “surrogate” distribution. From model likelihood and model prior, we can find how close two distributions are using KL-Divergence measure.\n",
        "\n",
        "From KL-Divergence formula, we try to use ELBO as loss function. \n",
        "\n",
        "ELBO (evidence lower bound) is a loss function just like cross entropy or mean squared error to track how \"close\" we are to the distribution.\n",
        "\n"
      ],
      "metadata": {
        "id": "WIKic4BHjF8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_iterations = 15\n",
        "loss = 0\n",
        "\n",
        "for j in range(num_iterations):\n",
        "    loss = 0\n",
        "    for batch_id, data in enumerate(train_loader):\n",
        "        # calculate the loss and take a gradient step\n",
        "        loss += svi.step(data[0].view(-1,28*28), data[1])\n",
        "    normalizer_train = len(train_loader.dataset)\n",
        "    total_epoch_loss_train = loss / normalizer_train\n",
        "    \n",
        "    print(\"Epoch \", j, \" Loss \", total_epoch_loss_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_rK6nZ7PFfB",
        "outputId": "01de37f6-ea66-4b6e-d0f8-594a2cd89f79"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/primitives.py:406: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0  Loss  5214.822222446267\n",
            "Epoch  1  Loss  3803.7218564522427\n",
            "Epoch  2  Loss  2845.987932377672\n",
            "Epoch  3  Loss  2151.7373882872103\n",
            "Epoch  4  Loss  1647.7442601480006\n",
            "Epoch  5  Loss  1277.3082127123514\n",
            "Epoch  6  Loss  999.9699672053496\n",
            "Epoch  7  Loss  789.1841042769591\n",
            "Epoch  8  Loss  627.7216931297144\n",
            "Epoch  9  Loss  502.2283314657847\n",
            "Epoch  10  Loss  404.6503089343707\n",
            "Epoch  11  Loss  329.55994814240137\n",
            "Epoch  12  Loss  269.4030268874009\n",
            "Epoch  13  Loss  223.5314849398772\n",
            "Epoch  14  Loss  186.98078346862792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 10\n",
        "def predict(x):\n",
        "  \"\"\"Make different models based on num_samples and make predictions\"\"\"\n",
        "  sampled_models = [guide(None, None) for _ in range(num_samples)]\n",
        "  yhats = [model(x).data for model in sampled_models]\n",
        "  mean = torch.mean(torch.stack(yhats), 0) #take model average of all classes for all models\n",
        "  return np.argmax(mean.numpy(), axis=1) #take that class whose max prob is there"
      ],
      "metadata": {
        "id": "zMfqlGgEP4BL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First thing to notice in the predict() function is that we’re using the learned guide() function (and not the model() function) to do predictions. This is because for model(), all we know is priors for weights and not the posterior. But for guide() after optimization iterations, the distribution given by the parameter values approximate the true posterior and so we can use it for predictions.\n",
        "\n",
        "Second thing to notice is that for each prediction, we’re sampling a new set of weights and parameters 10 times (given by num_samples). This effectively means that we’re sampling a new neural network 10 times for making one prediction. As you will see later, this is what enables us to give uncertainities on outputs. In the case above, to make a prediction, we’re averaging final layer output values of the 10 sampled nets for the given input and taking the max activation value as the predicted digit. \n",
        "\n"
      ],
      "metadata": {
        "id": "ul110_rckVXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But note that in above case, we’re forcing our net to make a prediction in each case. We haven’t used the magic of Bayes theorem to enable our net to say: “I refuse to make a prediction here”.\n",
        "\n",
        "To do that:\n",
        "\n",
        "1. For an input image, take 100 samples of neural networks to get 100 different output values from the last layer\n",
        "2. Convert those outputs (which are logsoftmaxed) into probabilities by exponentiating them\n",
        "3. Now, given the input image, for each digit we have 100 probability values\n",
        "4. We take median (50th percentile) of these 100 probability values as the threshold probability for each digit\n",
        "5. If the threshold probability is greater than 0.2, we select the digit as a classification output from the network"
      ],
      "metadata": {
        "id": "2jkUeNjGkho7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def give_uncertainities(x):\n",
        "  \"\"\"Give the output of different models without averaging or taking max \"\"\"\n",
        "  sampled_models = [guide(None, None) for _ in range(num_samples)]\n",
        "  yhats = [F.log_softmax(model(x.view(-1,28*28)).data, 1).detach().numpy() for model in sampled_models]\n",
        "  return np.asarray(yhats)"
      ],
      "metadata": {
        "id": "W0x4Elg9QA16"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uncertain_images = []\n",
        "\n",
        "for j, data in enumerate(test_loader):\n",
        "  certain = False \n",
        "  images, labels = data\n",
        "  for img in images:\n",
        "    predicted = predict(img.view(-1,28*28))\n",
        "    uncertainties = give_uncertainities(img)\n",
        "    for c in range(len(classes)):\n",
        "      histo_exp = []\n",
        "      #for each class, try to get probability from each model\n",
        "      for z in range(uncertainties.shape[0]):\n",
        "        histo_exp.append(np.exp(uncertainties[z][0][c])) #converting the outputs to probabilities\n",
        "\n",
        "      prob = np.percentile(histo_exp, 50) #sampling median probability for each class\n",
        "      if(prob > 0.2): #select if network thinks this sample is 20% chance of this being a class\n",
        "        certain = True \n",
        "\n",
        "    if not certain:\n",
        "      print(\"Actual class \",labels[0])\n",
        "      print(\"Predicted with low certainty as \",predicted, \" with probability \",prob)\n",
        "      show_image(img.reshape(28,28))\n",
        "      uncertain_images.append(img.reshape(28,28))\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "id": "iLbwWNZHUQ6d",
        "outputId": "cb6ffc12-e471-4dd3-8497-2ba490a0f174"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/primitives.py:406: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual class  tensor(8)\n",
            "Predicted with low certainty as  [8]  with probability  0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual class  tensor(7)\n",
            "Predicted with low certainty as  [4]  with probability  0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual class  tensor(8)\n",
            "Predicted with low certainty as  [8]  with probability  0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual class  tensor(6)\n",
            "Predicted with low certainty as  [6]  with probability  0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual class  tensor(0)\n",
            "Predicted with low certainty as  [0]  with probability  0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual class  tensor(0)\n",
            "Predicted with low certainty as  [0]  with probability  0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABYCAYAAACeV1sKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAFrUlEQVR4nO2cTWhUVxiGn7exWYhdNA2omJjEqBHdJBhKoV10UygqpOki1EWIuLBCIylko10VxY20wUixmNCIlUC7SFEXSiEhBVdFK2JjpGmoisY0UrCkLUpM8nUx9zpOTGYm83Pmx/PAYeaeM+fcL2+++52fezgyMzzZ5ZVcG/Ay4EV2gBfZAV5kB3iRHeBFdkBaIkt6X9JvksYlHcyUUcWGUh0nSyoBxoD3gPvAFWC3mY1mzrziYEUadd8Exs3sDwBJ3wFNwJIiSyramY+ZaamydMLFOuDec9f3g7wYJO2TdFXS1TTuVdCk48lJYWY9QA8UtyfHIx1PngAqn7uuCPI8C0hH5CvAJkk1kkqBj4ALmTGruEg5XJjZrKR24EegBOgzs5sZs6yISHkIl9LNijgmZ2t04UkSL7IDvMgO8CI7wIvsAC+yA7zIDvAiO8CL7AAvsgO8yA7I+npyNigvLweguroagP379yes09vbC8DU1NSi5ffuRd4/zM3NZcDCWLwnOyCvV+FKSkoAqK2tBWDnzp0AtLe3A1BTU5Mx2wYGBgA4cuQIACMjIwDMz88nVd+vwuWYvPTk9evXA9Dd3Q1AU1PTor8L4+j09HTCNi9fvgzArl27AKioqIj7+87OTgCOHz8OQCKdvCfnmLzy5MrKyHvZoaEhADZu3BhTPjMzA8DRo0cB6OvrA2BiIvn3t6EHNzY2AtDQ0ADAnj17YmwIaW1tBaC/vz9uu96Tc0xeefLp06cBaGtrA6Ieum5dZM/M48ePgei4+OzZsxmzraqqCoBLly4BsGXLFgDGx8cB2Lx5c9z68Tw5ryYj4SMb/uPPnTsHRMPE9u3bAVi5cmXG73337l0Aenp6AOjq6gJeDFmp4MOFA/IqXJw5cwaIdjazs7MAtLS0AFHPzgZhh3fx4kUAtm3bBsDt27eB6IRoKXzHl2PyypPDBZ/BwUEANmzYAESnuB0dHQAMDw+nbUs4lAv7gb1798bYEBJ2wok6We/JOSavPDkk7NHHxsZi8sNRxuhoZJ/5w4cPATh16lTSNoTDv7q6OiA6hV/IoUOHADh27Bjgp9V5T156crjEGU4ImpubATh8+HCWLItOOk6ePAnAiRMnAL/UWTAk9GRJlcC3wGrAgB4z65ZUBnwPVAN3gBYze5SgrZQemxUrIhPT+vp6AA4cOBBTXlZWBkQX9ZMhHHOHi03hsmkY55dLup48C3Sa2VbgLeATSVuBg8CQmW0ChoJrzyIsOyZLOg98FaR3zWxS0lrgJzOrS1A3Kx1AaWkpAGvWrHmWF46xnzx5AsCDBw9i6kxOTgLw9OnTjNiQsQUiSdVAA/AzsNrMJoOiP4mEk8Xq7AP2Lec+RYeZJZWAVcAvwIfB9d8Lyh8l0YYVa4r3dyc1upD0KjAA9JvZD0H2VBAmCD5T6zFeAhKKLEnAN8AtM+t6rugC0BZ8bwPOZ968IiGJR/wdIo/EDeB6kHYAbxAZVfwODAJlPlwsnvJyxleI+BlfjvEiO8CL7AAvsgO8yA7wIjvAi+wAL7IDvMgOcL0X7i/gv+CzUCnnRfur4lVwOq0GkHTVzBqd3jSDpGK/DxcO8CI7IBci9+Tgnplk2fY7j8kvIz5cOMCL7ABnIhfigdaSKiUNSxqVdFNSR5D/uaQJSdeDtCNuOy5icqEeaB28hV9rZtckvUZkS8QHQAvwr5l9kUw7rjz52YHWZjYDhAda5zVmNmlm14Lv/wC3WOSM6ES4EjmpA63zmQW7pwDaJd2Q1Cfp9Xh1fceXBJJWEdnc86mZTQNfA7VAPTAJfBmvviuRC/ZA68V2T5nZlJnNmdk80EskHC6JK5EL8kDrpXZPhdvTApqBkXjtOFnqLOADrd8GWoFfJV0P8j4DdkuqJ7J76A7wcbxG/LTaAb7jc4AX2QFeZAd4kR3gRXaAF9kBXmQH/A+kXgTgD0NSFQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual class  tensor(9)\n",
            "Predicted with low certainty as  [9]  with probability  2.2113408950535826e-15\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}